{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import numba\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from librosa.sequence import dtw\n",
    "from matplotlib import gridspec\n",
    "from speechCommon import *\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_dir = '../ttemp/TamperingDetection/hyp'\n",
    "all_ids = '../ttemp/TamperingDetection/data/cfg_files/all.ids'\n",
    "train_ids = '../ttemp/TamperingDetection/data/cfg_files/train.ids'\n",
    "\n",
    "editTimeSec = 1\n",
    "\n",
    "base_dir = \"../ttemp/TamperingDetection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates pairwise cost matrix between reference and query mfcc matrices \n",
    "\n",
    "def dist(query_id, editTimeSec, edit_type, piece):\n",
    "    mfcc_ref = readMFCC(base_dir, query_id, piece_type = 'reference')\n",
    "    mfcc_query = readMFCC(base_dir, query_id, piece_type = 'queries', edit_type=edit_type+str(piece), editTimeSec = editTimeSec)\n",
    "    \n",
    "    C = euclidean_distances(mfcc_query, mfcc_ref)\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True)\n",
    "def NWTWDP(C, alpha, beta=20, gamma = 1):\n",
    "    # 0: visible, 1: hidden\n",
    "    # B: 1 Diag, 2 Right, 3 Up, 0 switch plane\n",
    "    # initialization\n",
    "    D = np.zeros((2, C.shape[0], C.shape[1]))\n",
    "    B = np.zeros((2, C.shape[0], C.shape[1]))\n",
    "    \n",
    "    # bottom rows\n",
    "    D[0, 0, :] = C[0, :]\n",
    "    D[1, 0, :] = np.inf\n",
    "    \n",
    "    # first cols\n",
    "    for i in range(1, C.shape[0]):\n",
    "        D[0, i, 0] = D[0, i-1, 0] + alpha\n",
    "        D[1, i, 0] = D[0, i, 0]\n",
    "        B[0, i, 0] = 3\n",
    "        B[1, i, 0] = 0\n",
    "        \n",
    "    # rest of the matrix\n",
    "    for i in range(1, C.shape[0]):\n",
    "        for j in range(1, C.shape[1]):\n",
    "        \n",
    "            # hidden\n",
    "            # diag visible -> hidden, right in hidden, up in hidden\n",
    "            costs = np.array([D[0, i-1, j-1] + gamma + alpha, np.inf, D[1, i, j-1] + gamma, D[1, i-1, j] + alpha])\n",
    "            D[1, i, j] = np.min(costs)\n",
    "            B[1, i, j] = np.argmin(costs)\n",
    "                \n",
    "            # visible\n",
    "            # hidden -> visible, diag\n",
    "            costs = np.array([D[1, i, j] + beta, D[0, i-1, j-1] + C[i, j]])\n",
    "            D[0, i, j] = np.min(costs)\n",
    "            B[0, i, j] = np.argmin(costs)\n",
    "            \n",
    "    return B, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@numba.jit(nopython=True)\n",
    "def backtrace3D(B, D):\n",
    "    p = 0\n",
    "    r = D.shape[1] - 1\n",
    "    c = np.argmin(D[0, -1])\n",
    "    path_3D = []\n",
    "    while r > 0:\n",
    "        path_3D.append([p,r,c])\n",
    "        if B[p, r, c] == 0 and p == 0:\n",
    "            p = 1\n",
    "            r -= 1\n",
    "            c -= 1\n",
    "        elif B[p, r, c] == 0 and p == 1:\n",
    "            p = 0\n",
    "        elif B[p, r, c] == 1:\n",
    "            r -= 1\n",
    "            c -= 1\n",
    "        elif B[p, r, c] == 2:\n",
    "            c -= 1\n",
    "        elif B[p, r, c] == 3:\n",
    "            r -= 1\n",
    "    return np.asarray(path_3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aligns a query file with its corresponding reference file and returns the 3-D path throught the HSTW tensor\n",
    "def alignNWTWDP3D(query_id, editTimeSec, edit_type, piece, Ca = 2.4, Cb = 33, gamma = 3):\n",
    "    C = dist(query_id, editTimeSec, edit_type, piece)\n",
    "    alpha = np.median(np.min(C, axis=1)) * Ca\n",
    "    B, D = NWTWDP(C, alpha, beta=(alpha+gamma)*Cb)\n",
    "    path_3D = backtrace3D(B, D)\n",
    "    return path_3D, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aligns a query file with its corresponding reference file and returns the 3-D path throught the DTW matrix\n",
    "# Used for debugging\n",
    "def alignDTW(query_id, edit_type, piece, weightSet = 'D1'):\n",
    "    mfcc_ref = readMFCC(base_dir, query_id, piece_type = 'reference')\n",
    "    mfcc_query = readMFCC(base_dir, query_id, piece_type = 'queries', edit_type=edit_type+str(piece), editTimeSec = editTimeSec)\n",
    "    D, wp = dtw(mfcc_query.T, mfcc_ref.T, subseq=True, step_sizes_sigma=sigma, weights_mul=dtw_weights[weightSet])\n",
    "    return wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots HSTW alignment along with DTW alignment\n",
    "\n",
    "def plotHSTWAlignment(query_id, editTimeSec, edit_type, piece, endLim = 10**6):\n",
    "    startTime = time.time()\n",
    "    path_3D, C = alignNWTWDP3D(query_id, editTimeSec, edit_type, piece, Ca = 2.4, Cb = 33, gamma = 3)\n",
    "    path_d = alignDTW(query_id, edit_type, piece)\n",
    "    print(time.time() - startTime)\n",
    "\n",
    "    path_v = path_3D[np.where(path_3D[:,0] == 0)][:,1:3]\n",
    "    path_h = path_3D[np.where(path_3D[:,0] == 1)][:,1:3]\n",
    "\n",
    "    fig, ax = plt.subplots(1,2, figsize = (20,8))\n",
    "    plt.suptitle(\"{}-{}sec-{}{}\".format(query_id,editTimeSec,edit_type,piece))\n",
    "    ax[0].imshow(C[:,:endLim], aspect = 'auto', origin = 'lower')\n",
    "    ax[0].scatter(path_v[:,1], path_v[:,0], color = 'b', s = 0.5, alpha = 0.3)\n",
    "    ax[0].scatter(path_h[:,1], path_h[:,0], color = 'r', s = 0.5, alpha = 0.3)\n",
    "    ax[0].legend(['visible','hidden'])\n",
    "\n",
    "    ax[1].imshow(C[:,:endLim], aspect = 'auto', origin = 'lower')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saves alignment for a specific query and its reference file.\n",
    "\n",
    "def alignAndSave(filename, query_id, editTimeSec, edit_type, piece, Ca, Cb, gamma):\n",
    "    if query_id == '00' or piece in [11, 12, 13]:\n",
    "        return\n",
    "    print(filename)\n",
    "    if not os.path.exists(filename):\n",
    "    #if True:\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        path_3D, C = alignNWTWDP3D(query_id, editTimeSec, edit_type, piece, Ca = Ca, Cb = Cb, gamma = gamma)\n",
    "        path_3D = np.hstack((path_3D[:,1:3], path_3D[:,0,None]))\n",
    "        elem = path_3D[0]\n",
    "        prevPlane = elem[2]\n",
    "        costs = [C[elem[0], elem[1]]]\n",
    "        for elem in path_3D[1:]:\n",
    "            curPlane = elem[2]\n",
    "            if(curPlane == 0 and prevPlane == 1):\n",
    "                continue\n",
    "            else:\n",
    "                costs.append(C[elem[0], elem[1]])\n",
    "                \n",
    "        res = {}\n",
    "        res['wp'] = path_3D\n",
    "        res['dist'] = np.asarray(costs)\n",
    "        res['size'] = C.shape\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Saves all alignments for a specified benchmark\n",
    "\n",
    "def alignBenchmarkWithParams(benchmark, editTimeSec, editTypes, Ca, Cb, gamma):\n",
    "    with open ('../ttemp/TamperingDetection/cfg_files/{}.ids'.format(benchmark), 'r') as f:\n",
    "        for i, query_id in enumerate(f.read().split('\\n')):\n",
    "            if(query_id == ''):\n",
    "                continue\n",
    "            print(i, query_id)\n",
    "            for edit_type in editTypes:\n",
    "                for piece in range(1, 11):\n",
    "                    fileFolder = 'HSTW-{}-{}-{}'.format(Ca,Cb, gamma)\n",
    "                    filename = '{}/{}/{}sec/{}/{}_{}{}.pkl'.format(hyp_dir, benchmark, editTimeSec, fileFolder, query_id, edit_type, piece)\n",
    "                    if not os.path.exists(filename):\n",
    "                        print('aligning', query_id, edit_type, piece)\n",
    "                        alignAndSave(filename, query_id, editTimeSec, edit_type, piece, Ca, Cb, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runs alignment on all queries \n",
    "\n",
    "editTypes = ['i','r','d','n']\n",
    "editTimeSec = 1\n",
    "paramsList = [[2.4,33,3]]\n",
    "\n",
    "for params in paramsList:\n",
    "    alignBenchmarkWithParams('test', editTimeSec, editTypes, params[0], params[1], params[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
