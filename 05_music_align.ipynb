{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af9a4173",
   "metadata": {},
   "source": [
    "# Run Partial Matching Baseline\n",
    "\n",
    "This notebook will run alignment algorithms on clean to modified audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "785724f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "import time\n",
    "import librosa as lb\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "import pickle\n",
    "import logging\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "from align_algs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61c5bea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_sec = 512 * 1 / 22050\n",
    "n_cores = 8\n",
    "downsample = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c088816",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.array([5, 10, 15, 20, 25, 30])\n",
    "featdir1_root = Path('/home/cchang/ttmp/features/partial_match')\n",
    "featdir2 = Path('/home/cchang/ttmp/features/clean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "981ec3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set which cfg file we want to use for our tests\n",
    "cfg_options = ['toy', 'small', 'medium', 'train_benchmark', 'test_benchmark']\n",
    "cfg = cfg_options[1]\n",
    "\n",
    "if cfg == 'toy':\n",
    "    query_list = 'cfg_files/query.train_toy.list'\n",
    "elif cfg == 'small':\n",
    "    query_list = 'cfg_files/query.train_small.list'\n",
    "elif cfg == 'medium':\n",
    "    query_list = 'cfg_files/query.train_medium.list'\n",
    "elif cfg == 'train_benchmark':\n",
    "    query_list = 'cfg_files/query.train.list'\n",
    "elif cfg == 'test_benchmark':\n",
    "    query_list = 'cfg_files/query.test.list'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b53022e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a42526f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def align_batch(system, querylist, featdir1, featdir2, outdir, n_cores=8, downsample=1, verbose=False, **kwargs):\n",
    "#     '''\n",
    "#     Wrapper function for batch alignment that accepts a parameter for the baseline system number instead of parameters for steps and weights\n",
    "#     '''\n",
    "    \n",
    "#     if system==1:\n",
    "#         # Baseline 1: DTW with transitions (1,1), (1,2), (2,1) and weights 2, 3, 3\n",
    "#         steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "#         weights = np.array([2,3,3])\n",
    "#         inputs = alignDTW_batch(querylist, featdir1, featdir2, outdir, n_cores, steps, weights, downsample, verbose)\n",
    "        \n",
    "#     elif system==2:\n",
    "#         # Baseline 2: DTW with transitions (1,1), (1,2), (2,1) and weights 1, 1, 1\n",
    "#         steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "#         weights = np.array([1,1,1])\n",
    "#         inputs = alignDTW_batch(querylist, featdir1, featdir2, outdir, n_cores, steps, weights, downsample, verbose)\n",
    "        \n",
    "#     elif system==3:\n",
    "#         # Baseline 3: DTW with transitions (1,1), (1,0), (0,1) and weights 2, 1, 1\n",
    "#         steps = np.array([1,1,1,0,0,1]).reshape((-1,2))\n",
    "#         weights = np.array([2,1,1])\n",
    "#         inputs = alignDTW_batch(querylist, featdir1, featdir2, outdir, n_cores, steps, weights, downsample, verbose)\n",
    "        \n",
    "#     elif system==4:\n",
    "#         # Baseline 4: DTW with transitions (1,1), (1,0), (0,1) and weights 1, 1, 1\n",
    "#         steps = np.array([1,1,1,0,0,1]).reshape((-1,2))\n",
    "#         weights = np.array([1,1,1])\n",
    "#         inputs = alignDTW_batch(querylist, featdir1, featdir2, outdir, n_cores, steps, weights, downsample, verbose)\n",
    "        \n",
    "#     elif system==5:\n",
    "#         # Baseline 5: Subsequence DTW with (query, reference) transitions (1,1), (1,2), (2,1) and weights 1, 1, 2\n",
    "#         steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "#         weights = np.array([1,1,2])\n",
    "#         inputs = alignDTW_batch(querylist, featdir1, featdir2, outdir, n_cores, steps, weights, downsample, verbose, subseq=True)\n",
    "        \n",
    "#     elif system==6:\n",
    "#         # Baseline 6: NWTW\n",
    "#         gamma = 0.346\n",
    "#         inputs = alignNW_batch(querylist, featdir1, featdir2, outdir, n_cores, downsample, gamma)\n",
    "        \n",
    "# #     elif system==7:\n",
    "# #         # Baseline 7: Jump DTW with transitions (1,1), (1,0), (0,1) and weights 2, 1, 1 (same as 3)\n",
    "# # #         steps = np.array([1,1,1,0,0,1]).reshape((-1,2))\n",
    "# # #         weights = np.array([2,1,1])\n",
    "# #         steps = np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "# #         weights = np.array([2,3,3])\n",
    "# #         jumpweight = 1\n",
    "# #         jumplocsFile = kwargs['jumplocsFile'] # TODO: Add check for keyword\n",
    "# #         inputs = alignJumpDTW_batch(querylist, featdir1, featdir2, outdir, n_cores, steps, weights, jumplocsFile, jumpweight, downsample, subseq = False, sr=22050, hop=512)\n",
    "        \n",
    "#     else:\n",
    "#         logging.error('Unrecognized baseline ID (should be between 1 and 7) %s' % system)\n",
    "#         sys.exit(1)\n",
    "        \n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c76ab8c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def alignDTW_batch(querylist, featdir1, featdir2, outdir, n_cores, steps, weights, downsample, verbose = False, subseq = False, librosa = True):\n",
    "#     start = time.time()\n",
    "#     outdir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "#     # prep inputs for parallelization\n",
    "#     inputs = []\n",
    "#     with open(querylist, 'r') as f:\n",
    "#         for line in f:\n",
    "#             parts = line.strip().split(' ')\n",
    "#             assert len(parts) == 2\n",
    "#             featfile1 = (featdir1 / parts[0]).with_suffix('.npy')\n",
    "#             featfile2 = (featdir2 / parts[1]).with_suffix('.npy')\n",
    "#             queryid = os.path.basename(parts[0]) + '__' + os.path.basename(parts[1])\n",
    "#             outfile = (outdir / queryid).with_suffix('.pkl')\n",
    "            \n",
    "#             if os.path.exists(outfile):\n",
    "#                 print(f\"Skipping {outfile}\")\n",
    "#             else:\n",
    "#                 inputs.append((featfile1, featfile2, steps, weights, downsample, subseq, outfile, verbose, librosa))\n",
    "\n",
    "#     # process files in parallel\n",
    "#     with multiprocessing.get_context(\"spawn\").Pool(processes = n_cores) as pool:\n",
    "#         pool.starmap(alignDTW, inputs)\n",
    "#     print(\"Time to finish alignDTW: \", time.time() - start)\n",
    "#     return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9b7f65a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# @numba.jit(forceobj=True)\n",
    "# def alignDTW(featfile1, featfile2, steps, weights, downsample, subseq = False, outfile = None, verbose = False, librosa = True):\n",
    "#     '''\n",
    "#     Aligns featfile1 and featfile2\n",
    "    \n",
    "#     Arguments:\n",
    "#     subsequence -- if True, runs subsequenceDTW instead of DTW\n",
    "#     verbose -- if True, prints statements for each file while processing\n",
    "#     librosa -- if True, uses librosa's implementation of DTW\n",
    "#     '''\n",
    "#     if verbose:\n",
    "#         print(outfile)\n",
    "    \n",
    "#     # Read in chroma features from feature files\n",
    "#     F1 = np.load(featfile1) # 12 x N\n",
    "#     F2 = np.load(featfile2) # 12 x M\n",
    "    \n",
    "#     if verbose:\n",
    "#         print('Read chroma features')\n",
    "#         print(F1)\n",
    "#         print(F2)\n",
    "\n",
    "#     # Make sure there is a valid path possible. If one file is over twice as long as the other one, \n",
    "#     # then no valid path is possible (assuming our steps only let us move a max of 2 spaces)\n",
    "#     if max(F1.shape[1], F2.shape[1]) / min(F1.shape[1], F2.shape[1]) >= 2: # no valid path possible\n",
    "#         if verbose:\n",
    "#             print('Not valid')\n",
    "#         if outfile:\n",
    "#             pickle.dump(None, open(outfile, 'wb'))\n",
    "#         return None\n",
    "    \n",
    "#     if verbose:\n",
    "#         print('Checked if valid')\n",
    "    \n",
    "#     # For some reason, this calculation stalls for some pairs. Need to investigate more\n",
    "#     C = 1 - F1[:,0::downsample].T @ F2[:,0::downsample] # cos distance metric\n",
    "    \n",
    "#     if verbose:\n",
    "#         print('Calculated cost matrix if enabled')\n",
    "    \n",
    "#     # Run DTW algorithm\n",
    "    \n",
    "#     # This is Librosa's implementation\n",
    "#     if librosa:\n",
    "#         D, wp = lb.sequence.dtw(C=C, step_sizes_sigma = steps, weights_add = weights, subseq = subseq)\n",
    "# #         D, wp = lb.sequence.dtw(X=F1, Y=F2, metric='cosine', step_sizes_sigma = steps, weights_add = weights, subseq = subseq)\n",
    "#         wp = wp[::-1] # Need to reverse path for lb\n",
    "    \n",
    "#         # if N > M, Y can be a subsequence of X, librosa switches C to C transpose, so we want to switch the rows and columns of wp back\n",
    "#         if subseq and (F1.shape[1] > F2.shape[1]):\n",
    "#             wp = np.fliplr(wp)\n",
    "            \n",
    "#     else:\n",
    "#     # This is our implementation. Currently needs cost matrix as input to run\n",
    "#         optcost, wp = DTW(C, steps, weights, subseq = subseq)\n",
    "#     if verbose:\n",
    "#         print('Ran DTW')\n",
    "    \n",
    "#     # If output file is specified, save results\n",
    "#     if outfile:\n",
    "#         pickle.dump(wp, open(outfile, 'wb'))\n",
    "#         if verbose:\n",
    "#             print('Pickle dump')\n",
    "#     else:\n",
    "#         return wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bed9bd27",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# @numba.njit()\n",
    "# def DTW(C, steps, weights, subseq = False):\n",
    "#     '''\n",
    "#     Find the optimal subsequence path through cost matrix C.\n",
    "    \n",
    "#     Arguments:\n",
    "#     C -- cost matrix of dimension (# query frames, # reference frames)\n",
    "#     steps -- a numpy matrix specifying the allowable transitions.  It should be of\n",
    "#             dimension (L, 2), where each row specifies (row step, col step)\n",
    "#     weights -- a vector of size L specifying the multiplicative weights associated \n",
    "#                 with each of the allowable transitions\n",
    "#     subsequence -- if True, runs subsequence DTW instead of regular DTW\n",
    "                \n",
    "#     Returns:\n",
    "#     optcost -- the optimal subsequence path score\n",
    "#     path -- a matrix with 2 columns specifying the optimal subsequence path.  Each row \n",
    "#             specifies the (row, col) coordinate.\n",
    "#     '''\n",
    "#     D = np.zeros(C.shape)\n",
    "#     B = np.zeros(C.shape, dtype=np.int8)\n",
    "#     if subseq:\n",
    "#         D[0,:] = C[0,:]\n",
    "#     else:\n",
    "#         D[0,0] = C[0,0]\n",
    "#     for row in range(1,C.shape[0]):\n",
    "#         for col in range(C.shape[1]):\n",
    "#             mincost = np.inf\n",
    "#             minidx = -1\n",
    "#             for stepidx, step in enumerate(steps):\n",
    "#                 (rstep, cstep) = step\n",
    "#                 prevrow = row - rstep\n",
    "#                 prevcol = col - cstep\n",
    "#                 if prevrow >= 0 and prevcol >= 0:\n",
    "#                     pathcost = D[prevrow, prevcol] + C[row, col] * weights[stepidx]\n",
    "#                     if pathcost < mincost:\n",
    "#                         mincost = pathcost\n",
    "#                         minidx = stepidx\n",
    "#             D[row, col] = mincost\n",
    "#             B[row, col] = minidx\n",
    "            \n",
    "#     if subseq:\n",
    "#         optcost = np.min(D[-1,:])\n",
    "#     else:\n",
    "#         optcost = D[-1,-1]\n",
    "    \n",
    "#     path = backtrace(D, B, steps)\n",
    "#     path.reverse()\n",
    "#     path = np.array(path)\n",
    "    \n",
    "#     return optcost, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2ec0586",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # @numba.njit()\n",
    "# def backtrace(D, B, steps):\n",
    "#     '''\n",
    "#     Backtraces through the cumulative cost matrix D.\n",
    "    \n",
    "#     Arguments:\n",
    "#     D -- cumulative cost matrix\n",
    "#     B -- backtrace matrix\n",
    "#     steps -- a numpy matrix specifying the allowable transitions.  It should be of\n",
    "#             dimension (L, 2), where each row specifies (row step, col step)\n",
    "    \n",
    "#     Returns:\n",
    "#     path -- a python list of (row, col) coordinates for the optimal path.\n",
    "#     '''\n",
    "#     # initialization\n",
    "#     r = B.shape[0] - 1\n",
    "#     c = B.shape[1] - 1\n",
    "#     path = [[r, c]]\n",
    "    \n",
    "#     # backtrace\n",
    "#     while r > 0:\n",
    "#         step = steps[B[r, c]]\n",
    "#         r = r - step[0]\n",
    "#         c = c - step[1]\n",
    "#         if r != B.shape[0] - 1:\n",
    "#             path.append([r, c])\n",
    "            \n",
    "#     return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec85dc5f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from align_algs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6361927",
   "metadata": {},
   "source": [
    "## Calculate Alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "419c52c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to finish alignDTW:  1308.8862309455872\n",
      "Time to finish alignDTW:  1315.7620177268982\n",
      "Time to finish alignDTW:  1325.4251580238342\n",
      "Time to finish alignDTW:  1316.7038452625275\n",
      "Time to finish alignDTW:  1318.403090953827\n",
      "Time to finish alignDTW:  1326.2641677856445\n",
      "Time to finish alignDTW:  1324.1620078086853\n",
      "Time to finish alignDTW:  1322.9705564975739\n",
      "Time to finish alignDTW:  1325.3922770023346\n",
      "Time to finish alignDTW:  1328.6410856246948\n",
      "Time to finish alignDTW:  1325.11865067482\n",
      "Time to finish alignDTW:  1324.99085354805\n"
     ]
    }
   ],
   "source": [
    "# For DTW Baselines\n",
    "folder_names = ['dtw233', 'dtw111']\n",
    "for t in times:\n",
    "    EXPERIMENTS_ROOT = '/home/cchang/ttmp/partial_match/%s/experiments/align_clean_to_%ss' % (cfg, t)\n",
    "    \n",
    "    for i in range(1, len(folder_names) + 1):\n",
    "        outdir = Path(EXPERIMENTS_ROOT + \"/\" + folder_names[i-1])\n",
    "        featdir1 = featdir1_root / ('partial_match_%ss' % t)\n",
    "        inputs = align_batch(i, query_list, featdir1, featdir2, outdir, n_cores, downsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f329fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For NWTW\n",
    "folder_names = ['nwtw/gamma_0.8']\n",
    "gamma = 0.8\n",
    "for t in times[5:]:\n",
    "    EXPERIMENTS_ROOT = '/home/cchang/ttmp/partial_match/%s/experiments/align_clean_to_%ss' % (cfg, t)\n",
    "    \n",
    "    for i in range(1):\n",
    "        outdir = Path(EXPERIMENTS_ROOT + \"/\" + folder_names[i])\n",
    "        featdir1 = featdir1_root / ('partial_match_%ss' % t)\n",
    "#         inputs = align_batch(i, query_list, featdir1, featdir2, outdir, n_cores, downsample)\n",
    "        alignNW_batch(query_list, featdir1, featdir2, outdir, n_cores, downsample, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b957cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.array([5, 10, 15, 20, 25, 30])\n",
    "gamma = 20\n",
    "beta = 10\n",
    "steps = np.array([1,1,2,1,1,2]).reshape((-1,2))\n",
    "weights = np.array([2,3,3])\n",
    "folder_names = ['hstw/gamma_20_beta_10']\n",
    "n_cores = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13480fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hstw/gamma_20_beta_10']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec27d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For HSTW\n",
    "for t in times:\n",
    "    EXPERIMENTS_ROOT = '/home/cchang/ttmp/partial_match/%s/experiments/align_clean_to_%ss' % (cfg, t)\n",
    "    \n",
    "    for i in range(len(folder_names)):\n",
    "        outdir = Path(EXPERIMENTS_ROOT + \"/\" + folder_names[i])\n",
    "        featdir1 = featdir1_root / ('partial_match_%ss' % t)\n",
    "        align_HPTW_batch(query_list, featdir1, featdir2, outdir, n_cores, steps, weights, gamma, beta, downsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54dc79e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIR",
   "language": "python",
   "name": "mir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
