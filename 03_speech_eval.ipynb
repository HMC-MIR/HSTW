{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Use evalAllQueries fn to get and save ROC curve for whatever alignment we have, Generate Figure, Debug everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import librosa as lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalAllQueries(pairsFile, annotFile, pathsRoot, scoring_collar = 0.1, numThresholds = 1000, savefile = None):\n",
    "    insertionAttributions = []\n",
    "    deletionAttributions = []\n",
    "    replacementAttributions = []\n",
    "    \n",
    "    annotList = map(lambda x: x.split(), open(annotFile, 'r').readlines()) # I doubt this works but lets give it a go...\n",
    "    \n",
    "    with open(pairsFile, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            assert len(parts) == 2\n",
    "            \n",
    "            # Find correct annotations\n",
    "            queryId = os.path.basename(parts[0])\n",
    "            annot = findAnnot(annotList, queryId)\n",
    "            \n",
    "            # Find path\n",
    "            pathBasename = queryId + '__' + os.path.basename(parts[1])  # This will need to change based on file structure\n",
    "            pathFile = pathsRoot + '/' + pathBasename + '.pkl'\n",
    "            path = pkl.load(open(pathFile, 'rb'))\n",
    "\n",
    "            tamperType, theseAttributions = evalQuery(path, annot)\n",
    "            \n",
    "            # Add new costs and GT to\n",
    "            if tamperType == \"I\":\n",
    "                insertionAttributions += theseAttributions\n",
    "            elif tamperType == \"D\":\n",
    "                deletionAttributions += theseAttributions\n",
    "            else:\n",
    "                replacementAttributions += theseAttributions\n",
    "\n",
    "    # Get ROCs\n",
    "    insertionROC = calc_ROC(np.array(insertionAttributions), numTresholds)\n",
    "    deletionROC = calc_ROC(np.array(deletionAttributions), numTresholds)\n",
    "    replacementROC = calc_ROC(np.array(replacementAttributions), numTresholds)\n",
    "    \n",
    "    if savefile is not None:\n",
    "        pkl.dump([insertionROC, deletionROC, replacementROC], savefile)\n",
    "    \n",
    "    return [insertionROC, deletionROC, replacementROC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAnnot(annotList, queryId):\n",
    "    for annot in annotList:\n",
    "        if annotList[0] == queryId:\n",
    "            return annot\n",
    "    \n",
    "    print(\"Error: Annotations not found\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalQuery(path, annot, scoring_collar):\n",
    "    \n",
    "    tamperType = annot[4]\n",
    "    attributions = []\n",
    "    \n",
    "    # set up boundaries list (in seconds, relative to modified query)\n",
    "    # In form matchingRegionStart, tamperStart, tamperEnd, matchingRegionEndEnd\n",
    "    # This will depend on tamperType\n",
    "    if tamperType == \"I\":\n",
    "        insertionStart = int(annot[5])\n",
    "        insertionLength = int(annot[8]) - int(annot[7])\n",
    "        insertionEnd = insertionStart + insertionLength\n",
    "        offset = 0\n",
    "        \n",
    "        # I use +/- inf here to signal that the matching region extends to the first and last frames, and no scoring\n",
    "        # collar is needed\n",
    "        boundaries = [-float('inf'), insertionStart, insertionEnd, float('inf')]\n",
    "\n",
    "    elif tamperType == \"D\": # For deletions, also flip query and reference\n",
    "        queryPath = path[:,0]\n",
    "        refPath = path[:,1]\n",
    "        path[:,0] = refPath\n",
    "        path[:1] = queryPath\n",
    "        \n",
    "        deletionStart = annot[5]\n",
    "        deletionEnd = annot[6]\n",
    "        offset = annot[2]\n",
    "        matchEnd = annot[3] - offset\n",
    "        \n",
    "        # Here, the matching region starts and ends at the boundaries of the query recording\n",
    "        boundaries = [0, deletionStart, deletionEnd, matchEnd]\n",
    "        \n",
    "    \n",
    "    else: # replacement\n",
    "        replacementStart = annot[5]\n",
    "        replacementEnd = annot[6]\n",
    "        offset = 0\n",
    "        \n",
    "        # Again, the matching region will extend all the way to the first and last frames\n",
    "        boundaries = [-float('inf'), replacementStart, replacementEnd, float('inf')]\n",
    "    \n",
    "    query_length = path[-1, 0] # NOTE: May need to change this based on path format\n",
    "    \n",
    "    GT = getAttributionsGT(query_length, offset, boundaries, scoring_collar, hop_sec)\n",
    "\n",
    "    # Impute cost scores\n",
    "    # Interpolate here to fill in the frames that the path jumps over\n",
    "    costs = np.interp(np.arange(offset / hop_sec, query_length), path[:,0], path[:,2])\n",
    "    for i in range(gt.shape[0]):\n",
    "        if gt[i] >=0:\n",
    "            attributions.append([gt[i], costs[i]])\n",
    "            \n",
    "    return attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAttributionsGT(query_length, offset, boundaries, scoring_collar, hop_sec):\n",
    "    offsetFrames = offset / hop_sec\n",
    "    gt = np.zeros(query_length - offsetFrames)\n",
    "    \n",
    "    # Get the GT for each frame\n",
    "    # For now, just represent each frame with a single timestamp (at where the frame begins)\n",
    "    for frame in range(offset, query_length):\n",
    "        t_query = frame * hop_sec - offset\n",
    "        if withinCollar(t_query, boundaries, scoring_collar):\n",
    "            gt[frame] = -1\n",
    "        elif t_query < boundaries[0] or (t_query > boundaries[1] and t_query < boundaries[2]) or t_query > boundaries[3]:\n",
    "            gt[frame] = 1 # Non-matching region\n",
    "        else:\n",
    "            gt[frame] = 0\n",
    "            \n",
    "    return gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def withinCollar(t_query, boundaries, scoring_collar):\n",
    "    for t_boundary in boundaries:\n",
    "        if np.abs(t_query - t_boundary) < scoring_collar:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ROC(attributions, numThresholds):\n",
    "    '''\n",
    "    Calculates ROC curve for attributions based on number of thresholds\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    costs = attributions[:,1]\n",
    "    gt = attributions[:,0]\n",
    "        \n",
    "        \n",
    "    # Get minimum and max for thresholds\n",
    "    thresholdMin = np.min(costs)\n",
    "    thresholdMax = np.max(costs)\n",
    "    \n",
    "    thresholds = np.linspace(thresholdMin, thresholdMax, numThresholds)\n",
    "    ROC = np.ones((numThresholds,3))*-1\n",
    "    \n",
    "    # For each threshold, calculate false positive and false negative (miss) rate\n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        FPCountTot = 0\n",
    "        FNCountTot = 0\n",
    "        TrueNegCount = 0\n",
    "        TruePosCount = 0\n",
    "        \n",
    "        FPCount, FNCount = calcFPFN(costs, gt, threshold)\n",
    "\n",
    "        TrueNegCount += np.sum(gt == 1) # Note: Positive means match\n",
    "        TruePosCount += np.sum(gt == 0)\n",
    "\n",
    "        FPCountTot += FPCount\n",
    "        FNCountTot += FNCount\n",
    "        \n",
    "        # Threshold, False Positive, False Negative\n",
    "        ROC[i,:] = [threshold, FPCountTot/TrueNegCount, FNCountTot/TruePosCount]\n",
    "    \n",
    "    return ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcFPFN(costVec, gtAttribution, threshold):\n",
    "    '''\n",
    "    Calculate number of false positives and false negatives\n",
    "    '''\n",
    "    \n",
    "    # If cost is lower than threshold, then we consider sample in\n",
    "    # non tampered region (nontampered = 0, tampered = 1)\n",
    "    costHypVec = (costVec >= threshold).astype(int)\n",
    "\n",
    "    diffVec = (costHypVec - gtAttribution)\n",
    "\n",
    "    FPCount = np.sum((diffVec == -1).astype(int))\n",
    "    FNCount = np.sum((diffVec == 1).astype(int))\n",
    "\n",
    "    return FPCount, FNCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAttribution(timesToPlot, systemsToPlot):\n",
    "    fig, axs = plt.subplots(1, len(timesToPlot), figsize = (10, 7))\n",
    "\n",
    "    for i, plotTime in enumerate(timesToPlot):\n",
    "        x = np.arange(len(systemsToPlot))\n",
    "        numBars = len(3)\n",
    "        width = 0.75 / numBars\n",
    "        axs[i].grid(zorder=0)\n",
    "        insertions = []\n",
    "        deletions = []\n",
    "        replacements = []\n",
    "        for j, plotSys in enumerate(systemsToPlot):\n",
    "            \n",
    "            # Change to match file system ***\n",
    "            ROCfile = '/home/tshaw/ttmp/partial_match/%s/evaluations/alignment/align_clean_to_%ss/%s.pkl' \\\n",
    "                % (cfg, str(plotTime), plotSys)\n",
    "            # *******************************\n",
    "            \n",
    "            ROCs = pkl.load(ROCfile)\n",
    "            insertions.append(findEER(ROCs[0]))\n",
    "            deletions.append(findEER(ROCs[1]))\n",
    "            replacements.append(findEER(ROCs[2]))\n",
    "\n",
    "        axs[i].bar(x - width, np.array(insertions) * 100, width, zorder = 3)\n",
    "        axs[i].bar(x, np.array(deletions) * 100, width, zorder = 3)\n",
    "        axs[i].bar(x + width, np.array(replacements) * 100, width, zorder = 3)\n",
    "        \n",
    "        \n",
    "        axs[i].set_xlabel(\"System\")\n",
    "        axs[i].set_xticks(x)\n",
    "        axs[i].set_xticklabels(systemsToPlot)\n",
    "        axs[i].set_ylim(0,80)\n",
    "        axs[i].set_title(\"L = \" + str(plotTime))\n",
    "\n",
    "    plt.legend([\"Insertions\", \"Deletions\", \"Replacements\"], loc = (1.1, 0.5))\n",
    "    fig.suptitle(\"Attribution Error Rates\", fontsize = 'x-large')\n",
    "    axs[0].set_ylabel(\"Equal Error Rate (%)\", fontsize = \"large\")\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findEER(ROC):\n",
    "    '''\n",
    "    Calculates Equal Error Rate based on ROC\n",
    "    \n",
    "    '''\n",
    "    minDiff = np.inf\n",
    "    savedFP = 0\n",
    "    savedFN = 0\n",
    "\n",
    "    for rate in ROC:\n",
    "        FP = rate[1]\n",
    "        FN = rate[2]\n",
    "\n",
    "        if np.abs(FP - FN) < minDiff:\n",
    "            minDiff = np.abs(FP - FN)\n",
    "            savedFP = FP\n",
    "            savedFN = FN\n",
    "            \n",
    "    return savedFP, savedFN, minDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesToPlot = [4, 4, 4, 4]\n",
    "systemsToPlot = [\"dtw112\", \"dtw112\", \"dtw112\"]\n",
    "\n",
    "plotAttribution(timesToPlot, systemsToPlot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MIR",
   "language": "python",
   "name": "mir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
